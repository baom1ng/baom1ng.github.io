[{"id":"151d99aa718e6ed80f8a5120c08988a5","title":"Kubernetes1.27-containerd1.7集群安装","content":"Kubernetes1.27-containerd1.7集群安装\n\n\n\n\n主机名称\n操作系统\nIP地址\n说明\n\n\n\nMaster\nUbuntu 22.04.2 LTS\n192.168.10.15\n控制节点\n\n\nWork1\nUbuntu 22.04.2 LTS\n192.168.10.16\n工作节点1\n\n\nWork2\nUbuntu 22.04.2 LTS\n192.168.10.17\n工作节点2\n\n\n1.安装containerd(所有节点)根据系统和CPU类型选择cri-containerd-cni文件进行下载。下载完成后，将文件copy至主机。也可以直接使用wget命令下载。\n\n123456789101112131415161718# step 1: 从github上获取containerdsudo wget https://github.com/containerd/containerd/releases/download/v1.7.2/cri-containerd-1.7.2-linux-amd64.tar.gz# step 2: 解压tar xzf cri-containerd-cni-1.7.2-linux-amd64.tar.gz# step 3: 复制配置文件sudo cp etc/crictl.yaml /etc/sudo cp etc/systemd/system/containerd.service /etc/systemd/system/# step 4: 安装containerd 和相关依赖sudo cp usr/local/bin/* /usr/local/bin/sudo cp usr/local/sbin/* /usr/local/sbin/# step 5: 生成和配置启动文件sudo mkdir -p /etc/containerdsudo containerd config default &gt; /etc/containerd/config.tomlsudo sed -i &#x27;s#registry.k8s.io/pause:3.6#registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.9#g&#x27; /etc/containerd/config.tomlsudo sed -i &#x27;s#SystemdCgroup = false#SystemdCgroup = true#g&#x27;  /etc/containerd/config.toml# step 6: 重启containerd并设置开机启动sudo systemctl restart containerdsudo systemctl enable containerd\n\n2.主机初始化配置(所有节点)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 集群主机名sudo su# 使用sudo执行会失败，切换rootecho &quot;192.168.10.15  master&quot; &gt;&gt; /etc/hostsecho &quot;192.168.10.16  work1&quot; &gt;&gt; /etc/hostsecho &quot;192.168.10.17  work2&quot; &gt;&gt; /etc/hosts# 交换分区sudo sed -i &#x27;s/^\\(.*swap.*\\)$/#\\1/g&#x27; /etc/fstabsudo swapoff -a# 网络内核模块sudo tee /etc/modules-load.d/containerd.conf &lt;&lt;EOFoverlaybr_netfilterEOFsudo modprobe overlaysudo modprobe br_netfilter# 数据包转发sudo tee /etc/sysctl.d/kubernetes.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1EOFsudo sysctl --system# 配置 Kubernetes 集群相关的防火墙规则# 在主节点执行：sudo ufw allow 6443/tcpsudo ufw allow 2379/tcpsudo ufw allow 2380/tcpsudo ufw allow 10250/tcpsudo ufw allow 10251/tcpsudo ufw allow 10252/tcpsudo ufw allow 10255/tcpsudo ufw reload# 在工作节点执行：sudo ufw allow 10250/tcpsudo ufw allow 30000:32767/tcpsudo ufw reload# k8s源sudo apt updatesudo apt install -y apt-transport-https# 使用sudo执行会失败，切换rootsudo sucurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.listdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF# 安装k8ssudo apt updatesudo apt install -y kubelet kubeadm kubectl\n\n3.修改crictl配置文件(所有节点)123456# 修改crictl配置文件，获得containerd的sock信息，没有该文件的话创建一个cat /etc/crictl.yaml runtime-endpoint: unix:///run/containerd/containerd.sockimage-endpoint: unix:///run/containerd/containerd.socktimeout: 10debug: false\n\n4.初始化(控制节点)12sudo kubeadm init --kubernetes-version=1.27.2 --apiserver-advertise-address=192.168.10.15 --apiserver-bind-port=6443 --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 --cri-socket=unix:///run/containerd/containerd.sock#apiserver-advertise-address需要使用本机上网卡的ip，否则的话会导致etcd绑定ip失败启动不了，从而apiserver也启动不了\n\n初始化成功，显示如下信息\n123456789101112131415161718192021Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user:  mkdir -p $HOME/.kube  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run:  export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:  https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.10.15:6443 --token vo2r54.7jdugv0ivp91po0w \\\t--discovery-token-ca-cert-hash sha256:2b6ec05aa042aab6f2f51d6b9052fa062e265dc68707d416a7e341c05e79bd58\n\n执行上面的提示的命令\n123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n执行kubectl get node我们可以看到节点处于NotReady状态，需要安装flannel\n12345kubectl get nodeNAME     STATUS     ROLES           AGE   VERSIONmaster   NotReady   control-plane   42m   v1.27.2# 使用kubectl安装flannelkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml\n\n如果网络无法访问github可以手动创建kube-flannel.yml\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219apiVersion: v1kind: Namespacemetadata:  labels:    k8s-app: flannel    pod-security.kubernetes.io/enforce: privileged  name: kube-flannel---apiVersion: v1kind: ServiceAccountmetadata:  labels:    k8s-app: flannel  name: flannel  namespace: kube-flannel---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata:  labels:    k8s-app: flannel  name: flannelrules:- apiGroups:  - &quot;&quot;  resources:  - pods  verbs:  - get- apiGroups:  - &quot;&quot;  resources:  - nodes  verbs:  - get  - list  - watch- apiGroups:  - &quot;&quot;  resources:  - nodes/status  verbs:  - patch- apiGroups:  - networking.k8s.io  resources:  - clustercidrs  verbs:  - list  - watch---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  labels:    k8s-app: flannel  name: flannelroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: flannelsubjects:- kind: ServiceAccount  name: flannel  namespace: kube-flannel---apiVersion: v1data:  cni-conf.json: |    &#123;      &quot;name&quot;: &quot;cbr0&quot;,      &quot;cniVersion&quot;: &quot;0.3.1&quot;,      &quot;plugins&quot;: [        &#123;          &quot;type&quot;: &quot;flannel&quot;,          &quot;delegate&quot;: &#123;            &quot;hairpinMode&quot;: true,            &quot;isDefaultGateway&quot;: true          &#125;        &#125;,        &#123;          &quot;type&quot;: &quot;portmap&quot;,          &quot;capabilities&quot;: &#123;            &quot;portMappings&quot;: true          &#125;        &#125;      ]    &#125;  net-conf.json: |    &#123;      &quot;Network&quot;: &quot;10.244.0.0/16&quot;,      &quot;Backend&quot;: &#123;        &quot;Type&quot;: &quot;vxlan&quot;      &#125;    &#125;kind: ConfigMapmetadata:  labels:    app: flannel    k8s-app: flannel    tier: node  name: kube-flannel-cfg  namespace: kube-flannel---apiVersion: apps/v1kind: DaemonSetmetadata:  labels:    app: flannel    k8s-app: flannel    tier: node  name: kube-flannel-ds  namespace: kube-flannelspec:  selector:    matchLabels:      app: flannel      k8s-app: flannel  template:    metadata:      labels:        app: flannel        k8s-app: flannel        tier: node    spec:      affinity:        nodeAffinity:          requiredDuringSchedulingIgnoredDuringExecution:            nodeSelectorTerms:            - matchExpressions:              - key: kubernetes.io/os                operator: In                values:                - linux      containers:      - args:        - --ip-masq        - --kube-subnet-mgr        command:        - /opt/bin/flanneld        env:        - name: POD_NAME          valueFrom:            fieldRef:              fieldPath: metadata.name        - name: POD_NAMESPACE          valueFrom:            fieldRef:              fieldPath: metadata.namespace        - name: EVENT_QUEUE_DEPTH          value: &quot;5000&quot;        image: docker.io/flannel/flannel:v0.22.0        name: kube-flannel        resources:          requests:            cpu: 100m            memory: 50Mi        securityContext:          capabilities:            add:            - NET_ADMIN            - NET_RAW          privileged: false        volumeMounts:        - mountPath: /run/flannel          name: run        - mountPath: /etc/kube-flannel/          name: flannel-cfg        - mountPath: /run/xtables.lock          name: xtables-lock      hostNetwork: true      initContainers:      - args:        - -f        - /flannel        - /opt/cni/bin/flannel        command:        - cp        image: docker.io/flannel/flannel-cni-plugin:v1.1.2        name: install-cni-plugin        volumeMounts:        - mountPath: /opt/cni/bin          name: cni-plugin      - args:        - -f        - /etc/kube-flannel/cni-conf.json        - /etc/cni/net.d/10-flannel.conflist        command:        - cp        image: docker.io/flannel/flannel:v0.22.0        name: install-cni        volumeMounts:        - mountPath: /etc/cni/net.d          name: cni        - mountPath: /etc/kube-flannel/          name: flannel-cfg      priorityClassName: system-node-critical      serviceAccountName: flannel      tolerations:      - effect: NoSchedule        operator: Exists      volumes:      - hostPath:          path: /run/flannel        name: run      - hostPath:          path: /opt/cni/bin        name: cni-plugin      - hostPath:          path: /etc/cni/net.d        name: cni      - configMap:          name: kube-flannel-cfg        name: flannel-cfg      - hostPath:          path: /run/xtables.lock          type: FileOrCreate        name: xtables-lock\n\n执行完后，查看flannel是否启动成功\n1234kubectl get pods -n kube-flannelNAME                    READY   STATUS    RESTARTS      AGEkube-flannel-ds-7vqgt   1/1     Running   0             32mkube-flannel-ds-b9n72   1/1     Running   3 (84s ago)   8m20s\n\n查看节点状态,显示ready\n1234kubectl get nodeNAME     STATUS   ROLES           AGE   VERSIONmaster   Ready    control-plane   86m   v1.27.2work1    Ready    &lt;none&gt;          15m   v1.27.2\n\n5.将work节点加入集群(所有work节点)1sudo kubeadm join 192.168.10.15:6443 --token 6zw8z1.7j90zp477rv2kct6 --discovery-token-ca-cert-hash sha256:2b6ec05aa042aab6f2f51d6b9052fa062e265dc68707d416a7e341c05e79bd58\n\n执行完成后我们再主节点产看nodes\n12345kubectl get  nodesNAME     STATUS   ROLES           AGE     VERSIONmaster   Ready    control-plane   96m     v1.27.2work1    Ready    &lt;none&gt;          25m     v1.27.2work2    Ready    &lt;none&gt;          7m25s   v1.27.2\n\n这里显示所有节点Ready表示k8s集群安装成功\n","slug":"Kubernetes1-27-containerd1-7集群安装","date":"2023-02-19T02:39:13.000Z","categories_index":"Kubernetes","tags_index":"Kubernetes","author_index":"Brevin"},{"id":"0361f9a39ac53c480f13924da3215802","title":"Docker-Compose","content":"简介Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。\n其代码目前在 https://github.com/docker/compose 上开源。\nCompose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。\n通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。\nCompose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。\nCompose 中有两个重要的概念：\n\n服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。\n项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。\n\nCompose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。\nCompose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。\n安装与卸载1.linux\n在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。\n\n12$ curl -SL https://github.com/docker/compose/releases/download/v2.12.2/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose$ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\n\n2.macos、window\nCompose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。\n\n3.测试安装成功12$ docker-compose -vDocker Compose version v2.11.2\n\n4.卸载\n如果是二进制包方式安装的，删除二进制文件即可。\n\n1$ sudo rm /usr/local/bin/docker-compose\n\ndocker compose使用1# 1.相关概念\n\n首先介绍几个术语。\n\n服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。\n项目 (project)：由一组关联的应用容器组成的一个完整业务单元。∂一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。\n\n1# 2.场景\n\n最常见的项目是 web 网站，该项目应该包含 web 应用和缓存。\n\nspringboot应用\nmysql服务\nredis服务\nelasticsearch服务\n…….\n\n12# 3.docker-compose模板- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/compose_file.html\n\n12345678910111213141516171819202122232425262728293031version: &quot;3.0&quot;services:  mysqldb:    image: mysql:5.7.19    container_name: mysql    ports:      - &quot;3306:3306&quot;    volumes:      - /root/mysql/conf:/etc/mysql/conf.d      - /root/mysql/logs:/logs      - /root/mysql/data:/var/lib/mysql    environment:      MYSQL_ROOT_PASSWORD: root    networks:      - ems    depends_on:      - redis  redis:    image: redis:4.0.14    container_name: redis    ports:      - &quot;6379:6379&quot;    networks:      - ems    volumes:      - /root/redis/data:/data    command: redis-server    networks:  ems:\n\n12# 4.通过docker-compose运行一组容器- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/commands.html\n\n12[root@centos ~]# docker-compose up    \t\t\t\t\t\t\t//前台启动一组服务[root@centos ~]# docker-compose up -d \t\t\t\t\t\t\t//后台启动一组服务\n\n\ndocker-compose 模板文件模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。\n默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。\n123456789version: &quot;3&quot;services:  webapp:    image: examples/web    ports:      - &quot;80:80&quot;    volumes:      - &quot;/data&quot;\n\n注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。\n如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中重复设置。\n下面分别介绍各个指令的用法。\nbuild指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。\n12345version: &#x27;3&#x27;services:  webapp:    build: ./dir\n\n你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。\n使用 dockerfile 指令指定 Dockerfile 文件名。\n使用 arg 指令指定构建镜像时的变量。\n123456789version: &#x27;3&#x27;services:  webapp:    build:      context: ./dir      dockerfile: Dockerfile-alternate      args:        buildno: 1\n\ncommand覆盖容器启动后默认执行的命令。\n1command: echo &quot;hello world&quot;\n\ncontainer_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。\n1container_name: docker-web-container\n\n\n\n\n\n\n\n\n\n\n注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。\ndepends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web\n1234567891011121314version: &#x27;3&#x27;services:  web:    build: .    depends_on:      - db      - redis  redis:    image: redis  db:    image: postgres\n\n\n\n\n\n\n\n\n\n\n注意：web 服务不会等待 redis db 「完全启动」之后才启动。\nenv_file从文件中获取环境变量，可以为单独的文件路径或列表。\n如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。\n如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。\n123456env_file: .envenv_file:  - ./common.env  - ./apps/web.env  - /opt/secrets.env\n\n环境变量文件中每一行必须符合格式，支持 # 开头的注释行。\n12# common.env: Set development environmentPROG_ENV=development\n\nenvironment设置环境变量。你可以使用数组或字典两种格式。\n只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。\n1234567environment:  RACK_ENV: development  SESSION_SECRET:environment:  - RACK_ENV=development  - SESSION_SECRET\n\n如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括\n1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF\n\nhealthcheck通过命令检查容器是否健康运行。\n12345healthcheck:  test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;]  interval: 1m30s  timeout: 10s  retries: 3\n\nimage指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。\n123image: ubuntuimage: orchardup/postgresqlimage: a4bc65fd\n\nnetworks配置容器连接的网络。\n1234567891011version: &quot;3&quot;services:  some-service:    networks:     - some-network     - other-networknetworks:  some-network:  other-network:\n\nports暴露端口信息。\n使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。\n12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot;\n\n注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。\nsysctls配置容器内核参数。\n1234567sysctls:  net.core.somaxconn: 1024  net.ipv4.tcp_syncookies: 0sysctls:  - net.core.somaxconn=1024  - net.ipv4.tcp_syncookies=0\n\nulimits指定容器的 ulimits 限制值。\n例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。\n12345ulimits:  nproc: 65535  nofile:    soft: 20000    hard: 40000\n\nvolumes数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。\n该指令中路径支持相对路径。\n1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro\n\n如果路径为数据卷名称，必须在文件中配置数据卷。\n12345678910version: &quot;3&quot;services:  my_src:    image: mysql:8.0    volumes:      - mysql_data:/var/lib/mysqlvolumes:  mysql_data:\n\n\ndocker-compose 常用命令1. 命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。\n执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。\ndocker-compose 命令的基本的使用格式是\n1docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...]\n\n2. 命令选项\n-f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。\n-p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。\n--x-networking 使用 Docker 的可拔插网络后端特性\n--x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge\n--verbose 输出更多调试信息。\n-v, --version 打印版本并退出。\n\n3.命令使用说明up格式为 docker-compose up [options] [SERVICE...]。\n\n该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。\n\n链接的服务都将会被自动启动，除非已经处于运行状态。\n\n可以说，大部分时候都可以直接通过该命令来启动一个项目。\n\n默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。\n\n当通过 Ctrl-C 停止命令时，所有容器将会停止。\n\n如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。\n\n默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容\n\n\n\ndown\n此命令将会停止 up 命令所启动的容器，并移除网络\n\n\nexec\n进入指定的容器。\n\n\nps格式为 docker-compose ps [options] [SERVICE...]。\n列出项目中目前的所有容器。\n选项：\n\n-q 只打印容器的 ID 信息。\n\n\nrestart格式为 docker-compose restart [options] [SERVICE...]。\n重启项目中的服务。\n选项：\n\n-t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。\n\n\nrm格式为 docker-compose rm [options] [SERVICE...]。\n删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。\n选项：\n\n-f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。\n-v 删除容器所挂载的数据卷。\n\n\nstart格式为 docker-compose start [SERVICE...]。\n启动已经存在的服务容器。\n\nstop格式为 docker-compose stop [options] [SERVICE...]。\n停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。\n选项：\n\n-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。\n\n\ntop查看各个服务容器内运行的进程。\n\nunpause格式为 docker-compose unpause [SERVICE...]。\n恢复处于暂停状态中的服务。\n\n","slug":"Docker-Compose","date":"2022-10-16T02:38:51.000Z","categories_index":"Docker","tags_index":"Docker","author_index":"Brevin"},{"id":"75603112ad785d198fb30f0b34b1d632","title":"Dockerfile","content":"Dockerfile1. 什么是DockerfileDockerfile可以认为是Docker镜像的描述文件，是由一系列命令和参数构成的脚本。主要作用是用来构建docker镜像的构建文件。\n\n\n通过架构图可以看出通过DockerFile可以直接构建镜像\n\n2. Dockerfile解析过程\n3 .Dockerfile的保留命令官方说明:https://docs.docker.com/engine/reference/builder/\n\n\n\n保留字\n作用\n\n\n\nFROM\n当前镜像是基于哪个镜像的 第一个指令必须是FROM\n\n\nMAINTAINER\n镜像维护者的姓名和邮箱地址\n\n\nRUN\n构建镜像时需要运行的指令\n\n\nEXPOSE\n当前容器对外暴露出的端口号\n\n\nWORKDIR\n指定在创建容器后，终端默认登录进来的工作目录，一个落脚点\n\n\nENV\n用来在构建镜像过程中设置环境变量\n\n\nADD\n将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar包\n\n\nCOPY\n类似于ADD，拷贝文件和目录到镜像中将从构建上下文目录中&lt;原路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置\n\n\nVOLUME\n容器数据卷，用于数据保存和持久化工作\n\n\nCMD\n指定一个容器启动时要运行的命令Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run之后的参数替换\n\n\nENTRYPOINT\n指定一个容器启动时要运行的命令ENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及其参数\n\n\n3.1 FROM 命令\n基于那个镜像进行构建新的镜像,在构建时会自动从docker hub拉取base镜像 必须作为Dockerfile的第一个指令出现\n\n语法:\n  123FROM  &lt;image&gt;FROM  &lt;image&gt;[:&lt;tag&gt;]     使用版本不写为latestFROM  &lt;image&gt;[@&lt;digest&gt;]  使用摘要\n\n3.2 MAINTAINER  命令\n镜像维护者的姓名和邮箱地址[废弃]\n\n语法:\n  1MAINTAINER &lt;name&gt;\n\n3.3 RUN 命令\nRUN指令将在当前映像之上的新层中执行任何命令并提交结果。生成的提交映像将用于Dockerfile中的下一步\n\n语法:\n  12345RUN &lt;command&gt; (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)RUN echo helloRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;]\n\n3.4 EXPOSE 命令\n用来指定构建的镜像在运行为容器时对外暴露的端口\n\n语法:\n  12EXPOSE 80/tcp  如果没有显示指定则默认暴露都是tcpEXPOSE 80/udp\n\n3.5 CMD 命令\n用来为启动的容器指定执行的命令,在Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。\n\n注意: Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。\n\n语法:\n  123CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form)CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT)CMD command param1 param2 (shell form)\n\n3.6 WORKDIR 命令\n用来为Dockerfile中的任何RUN、CMD、ENTRYPOINT、COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使它没有在任何后续Dockerfile指令中使用，它也将被创建。\n\n语法:\n  123456WORKDIR /path/to/workdirWORKDIR /aWORKDIR bWORKDIR c`注意:WORKDIR指令可以在Dockerfile中多次使用。如果提供了相对路径，则该路径将与先前WORKDIR指令的路径相对`\n\n3.7 ENV 命令\n用来为构建镜像设置环境变量。这个值将出现在构建阶段中所有后续指令的环境中。\n\n语法：\n  12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt; ...\n\n3.8 ADD 命令\n用来从context上下文复制新文件、目录或远程文件url，并将它们添加到位于指定路径的映像文件系统中。\n\n语法:\n  12345ADD hom* /mydir/       通配符添加多个文件ADD hom?.txt /mydir/   通配符添加ADD test.txt relativeDir/  可以指定相对路径ADD test.txt /absoluteDir/ 也可以指定绝对路径ADD url \n\n3.9 COPY 命令\n用来将context目录中指定文件复制到镜像的指定目录中\n\n语法:\n  12COPY src destCOPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]\n\n3.10 VOLUME 命令\n用来定义容器运行时可以挂在到宿主机的目录\n\n语法:\n  1VOLUME [&quot;/data&quot;]\n\n3.11 ENTRYPOINT命令\n用来指定容器启动时执行命令和CMD类似\n\n语法:\n  12[&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]ENTRYPOINT command param1 param2\n\n  ENTRYPOINT指令，往往用于设置容器启动后的第一个命令，这对一个容器来说往往是固定的。  CMD指令，往往用于设置容器启动的第一个命令的默认参数，这对一个容器来说可以是变化的。\n\n\nDockerfile构建HEXO项目部署1.编写Dockerfile123456789101112131415FROM centos:7RUN [&quot;yum&quot;,&quot;install&quot;,&quot;-y&quot;,&quot;git&quot;,&quot;vim&quot;]WORKDIR /home/hexoEXPOSE 4000#安装nodejsADD https://nodejs.org/dist/v16.13.2/node-v16.13.2-linux-x64.tar.xz /homeRUN mkdir -p /usr/local/lib/nodejsRUN tar -xJvf /home/node*.tar.xzRUN mv node-*-linux-x64 /usr/local/nodejs ENV PATH=$PATH:&#x27;/usr/local/nodejs/bin&#x27;#安装hexoRUN npm install hexo-cli -gENV PATH=&quot;$PATH:./node_modules/.bin&quot;RUN hexo initCMD hexo server\n\n2.构建镜像1[root@localhost ems]# docker build -t hexo1.0 .\n\n3.运行镜像1[root@localhost ems]# docker run -d -p 8080:4000 --name hexo hexo1.0\n\n4.访问项目1http://127.0.0.1:4000\n\n\n\n\n","slug":"Dockerflie","date":"2022-10-01T06:21:20.000Z","categories_index":"Docker","tags_index":"Docker","author_index":"Brevin"},{"id":"2e8be22ca0c67568a1ab56634abc99c8","title":"Docker网络详解","content":"\n理解Docker0ip addr #查看本机网络网卡有三个网络问题：Docker是如何处理容器网络访问的？\n1234567891011121314151617181920212223242526[root@vm22 ~]# docker run -d -P --name tomcat01 tomcat#查看容器内部网络地址 ip addr 或者 dcoker inspect[root@vm22 ~]# docker inspect tomcat01&quot;Networks&quot;: &#123;                &quot;bridge&quot;: &#123;                    &quot;IPAMConfig&quot;: null,                    &quot;Links&quot;: null,                    &quot;Aliases&quot;: null,                    &quot;NetworkID&quot;: &quot;2893fe225a852d859fb8e831ff668623b9f220c3f47a8b1b83bb31691a8961b5&quot;,                    &quot;EndpointID&quot;: &quot;a6dca6dc3b938d365f9e0cffdc0944e0ce94dd980c5cde5826dfaf6ce3323ea5&quot;,                    &quot;Gateway&quot;: &quot;172.17.0.1&quot;,                    &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,  # Docker分配的ip地址                    &quot;IPPrefixLen&quot;: 16,                    &quot;IPv6Gateway&quot;: &quot;&quot;,                    &quot;GlobalIPv6Address&quot;: &quot;&quot;,                    &quot;GlobalIPv6PrefixLen&quot;: 0,                    &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,                    &quot;DriverOpts&quot;: null                &#125;            &#125;# 可以看到我在Linux上可以ping通容器[root@vm22 ~]# ping 172.17.0.2PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.729 ms64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.111 ms64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.135 ms\n原理：\n我们每启动一个docker容器，docker就会给容器分配一个IP地址，我们只要安装了docker，就会有一个网卡docker0。\n\n\nDocker 桥接模式，使用了evth-pair技术！\n\n\n我们每启动一个容器，我们的主机就就会多一对网卡2. 我们发现容器的网卡都是成对的\n\nevth-pair 就是一对的虚拟设备接口，他们都是成对出现的，一端连接协议，一端相互连接\n正因为有这个特性，evth-pair 充当一个桥梁，连接各种虚拟网络设备\nOpenstac，Docker容器之间的连接，OVS的连接，都使用 ecth-pair 技术\n\n\n容器之间是可以互相通讯的1234root@7f57cd426938:/usr/local/tomcat# ping 172.17.0.3PING 172.17.0.3 (172.17.0.3) 56(84) bytes of data.64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.104 ms64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.113 ms\n结论：tomcat01和tomcat02公用一个路由docker0\n\n\n\n\n\n\n\n\n小结Docker使用的Linux的桥接网络，宿主机中是一个Docker容器的网桥 Docker0\n\n\n\nDocker中的所有网络接口都是虚拟的。\n只要删除容器，对应的网桥就被删除。–link\n\n\n\n\n\n\n\n\n\n\n在我们搭建服务中，database url=IP，项目不重启，但是数据库ip换掉了，针对这种情况我们可以使用容器的名称来访问容器。\n1234567891011121314151617# 我们直接通过容器的名称去ping发现ping不通[root@vm22 ~]# docker exec -it tomcat01 ping tomcat02ping: tomcat02: No address associated with hostname# 在启动容器时使用--link命令将tomcat02和tomcat03进行连接[root@vm22 ~]# docker run -d -P --name tomcat03 --link tomcat02 tomcat:full75659bb40133489c9c6e14bd33bc30325cd1449fadec648f7e8fdf8a0b0e2a32# 使用--link命令后我们发现tomcat03可以直接通过容器名称连接tomcat02[root@vm22 ~]# docker exec -it tomcat03 ping tomcat02PING tomcat02 (172.17.0.3) 56(84) bytes of data.64 bytes from tomcat02 (172.17.0.3): icmp_seq=1 ttl=64 time=0.176 ms64 bytes from tomcat02 (172.17.0.3): icmp_seq=2 ttl=64 time=0.074 ms#但是我们反向无法ping通[root@vm22 ~]# docker exec -it tomcat02 ping tomcat03ping: tomcat03: No address associated with hostname\n我们可以看到在tomcat03中配置了tomcat02的地址\n123456789[root@vm22 ~]# docker exec -it tomcat03 cat /etc/hosts127.0.0.1       localhost::1     localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.3      tomcat02 0f01224e35e7172.17.0.4      75659bb40133\n–link 就是我们在hosts中增加了一个tomcat02的映射我们实际使用中不建议使用 –link，我们使用自定义网络来实现容器之前的互联\n自定义网络\n\n\n\n\n\n\n\n\n\n查看所有的Docker网络\n12345[root@vm22 ~]# docker network lsNETWORK ID     NAME      DRIVER    SCOPE2893fe225a85   bridge    bridge    local9612893a759b   host      host      locald67b91c2d6f8   none      null      local\n网络模式bridge：桥接 docker（默认），自定义网络使用bridgenone：不配置网络host：和宿主机共享网络container：容器之间网络连通创建一个自定义网络\n12345678910111213141516171819# 自定义一个名为mynet的网络#  --driver bridge#  --subnet 192.168.0.0/24#  --gateway 192.168.0.1[root@vm22 ~]# docker network create --driver bridge --subnet 192.168.0.0/24 --gateway 192.168.0.1 mynetbe625b138967ed399a64b6a96fbaade1e702ed6c7c07f66b59528e8077e44339[root@vm22 ~]# docker network lsNETWORK ID     NAME      DRIVER    SCOPE2893fe225a85   bridge    bridge    local9612893a759b   host      host      localbe625b138967   mynet     bridge    locald67b91c2d6f8   none      null      local# 测试容器之间的连接[root@vm22 ~]# docker exec -it tomcat1 ping tomcat2PING tomcat2 (192.168.0.3) 56(84) bytes of data.64 bytes from tomcat2.mynet (192.168.0.3): icmp_seq=1 ttl=64 time=0.626 ms64 bytes from tomcat2.mynet (192.168.0.3): icmp_seq=2 ttl=64 time=0.218 ms\n网络连通123456789101112#在docker0上创建tomcat3[root@vm22 ~]# docker run -d -P --name tomcat3 tomcat:full5c7b8afd60f532a0a50fe570ffcad8a5a40cd0ab946ddc51449140a0dbbd776f#测试tomcat3是否能与tomcat1连通[root@vm22 ~]# docker exec -it tomcat3 ping tomcat1ping: tomcat1: No address associated with hostname#使用命令 docker network connect 连接两个网络[root@vm22 ~]# docker network connect mynet tomcat3[root@vm22 ~]# docker exec -it tomcat3 ping tomcat1PING tomcat1 (192.168.0.3) 56(84) bytes of data.64 bytes from tomcat1.mynet (192.168.0.3): icmp_seq=1 ttl=64 time=0.063 ms64 bytes from tomcat1.mynet (192.168.0.3): icmp_seq=2 ttl=64 time=0.263 ms\n如果需要容器间相互连接，就需要使用docker network connect连接！\n","slug":"Docker网络详解","date":"2021-10-29T02:23:20.000Z","categories_index":"Docker","tags_index":"Docker","author_index":"Brevin"},{"id":"6ec80148ccdf0bae5b573fc594b500be","title":"Docker的基础命令","content":"\n帮助命令\n123docker version             #显示docker的版本信息docker info                #显示dcoker的系统信息，包括镜像和容器的数量docker [命令] --help        #帮助命令\ndocker官方文档地址：https://docs.docker.com/compose/reference/\n镜像命令\ndocker images 查看所有本地主机上的镜像\n1234567891011121314[root@vm22 ~]# docker imagesREPOSITORY            TAG       IMAGE ID       CREATED         SIZEwaibi/centos          1.0       161ad1397191   7 hours ago     231MBtomcat                2.0       8663b1d60f71   8 hours ago     684MBnginx                 latest    605c77e624dd   9 months ago    141MB#解释REPOSITORY    镜像的仓库源TAG           镜像的标签IMAGE ID      镜像的IDCREATED       镜像的创建时间SIZE          镜像的大小#可选项-a --all      显示所有镜像-q --quiet    只显示景象ID\ndocker search 搜索镜像\n123456[root@vm22 ~]# docker search mysqlNAME                            DESCRIPTION                                     STARS     OFFICIAL   AUTOMATEDmysql                           MySQL is a widely used, open-source relation…   13234     [OK]       mariadb                         MariaDB Server is a high performing open sou…   5062      [OK]       #可选项--filter=starts=3000    #搜索出来镜像starts大于3000的镜像\ndocker pull 下载镜像\n12345678910111213141516171819下载镜像 $ docker pull 镜像名[:tag][root@vm22 ~]# docker pull mysqlUsing default tag: latest  #如果指定tag，将默认下载latestlatest: Pulling from library/mysql72a69066d2fe: Already exists  #分层下载93619dbc5b36: Already exists 99da31dd6142: Already exists 626033c43d70: Already exists 37d5d7efb64e: Already exists ac563158d721: Already exists d2ba16033dad: Already exists 688ba7d5c01a: Pull complete 00e060b6d11d: Pull complete 1c04857f594f: Pull complete 4d7cfa90e6ea: Pull complete e0431212d27d: Pull complete Digest: sha256:e9027fe4d91c0153429607251656806cc784e914937271037f7738bd5b8e7709 #签名Status: Downloaded newer image for mysql:latestdocker.io/library/mysql:latest #真实地址\ndocker rmi 删除镜像\n123[root@vm22 ~]# docker rmi -f 3218b38490ce #删除指定镜像[root@vm22 ~]# docker rmi -f IMAGE ID IMAGE ID #删除多个镜像[root@vm22 ~]# docker rmi -f $(docker images -aq) #删除全部镜像\n容器命令\n启动容器\n12345678910111213141516$ docker run IMAGE [COMMAND] [ARG...]# 参数说明--name=&quot;name&quot;  给容器命名-d  后台运行-it  使用交互方式运行，进入容器查看内容-p  指定容器端口 -p 8080:8080        -p 主机端口:容器端口        -p IP:主机端口:容器端口-P  随机指定端口#启动并进入容器[root@vm22 ~]# docker run -it centos /bin/bash[root@bdcf79e05d39 /]# ls  # 查看容器内的centosbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var[root@bdcf79e05d39 /]# exit  # 退出容器 exit\n列出所有正在运行的容器\n123456789# docker ps 命令-a # 列出当前正在运行的容器+历史运行过的容器-n=?  # 显示最近创建的容器-q  # 只显示容器ID[root@vm22 ~]# docker psCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES[root@vm22 ~]# docker ps -aCONTAINER ID   IMAGE     COMMAND       CREATED         STATUS                          PORTS     NAMESbdcf79e05d39   centos    &quot;/bin/bash&quot;   3 minutes ago   Exited (0) About a minute ago             brave_jepsen\n退出容器\n12exit  # 直接停止并退出容器Ctrl + P + Q  # 容器不停止退出\n删除容器\n12docker rm 容器id  #删除指定容器docker rm -f $(docker ps -aq)  # 删除所有容器\n启动和停止容器操作\n1234docker start 容器ID    # 启动容器docker stop 容器ID    # 停止当前正在运行的容器docker restart 容器ID    # 重启容器docker kill 容器ID    # 强制停止容器\n其他常用命令\n后台启动容器\n12# 命令 doceker run -d 镜像[root@vm22 ~]# docker run -d centos\n查看日志\n1234567891011121314docker logs -f -t --tail 容器# 测试[root@vm22 ~]# docker run -d centos /bin/bash -c &quot;while true;do echo print logs;sleep 1;done &quot;[root@vm22 ~]# docker psCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS     NAMES82bb167358c7   centos    &quot;/bin/bash -c &#x27;while…&quot;   34 seconds ago   Up 33 seconds             hungry_mclean# 显示日志  -tf   --tail number[root@vm22 ~]# docker logs -t -f --tail 4 82bb167358c72022-09-28T17:41:05.146127148Z print logs2022-09-28T17:41:06.151409147Z print logs2022-09-28T17:41:07.157108266Z print logs2022-09-28T17:41:08.161395599Z print logs\n查看容器中进程信息\n12345# 命令 docker top 容器ID[root@vm22 ~]# docker top 82bb167358c7UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMDroot                4773                4753                0                   01:39               ?                   00:00:00            /bin/bash -c while true;do echo print logs;sleep 1;doneroot                5172                4773                0                   01:44               ?                   00:00:00            /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 1\n 查看镜像的元数据\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209# 命令 docker inspect 容器ID[root@vm22 ~]# docker inspect 82bb167358c7[    &#123;        &quot;Id&quot;: &quot;82bb167358c7835cae235ad9d3ba2097e5d63ecd7286de50fb26061467d9ef4b&quot;,        &quot;Created&quot;: &quot;2022-09-28T17:39:20.314052558Z&quot;,        &quot;Path&quot;: &quot;/bin/bash&quot;,        &quot;Args&quot;: [            &quot;-c&quot;,            &quot;while true;do echo print logs;sleep 1;done &quot;        ],        &quot;State&quot;: &#123;            &quot;Status&quot;: &quot;running&quot;,            &quot;Running&quot;: true,            &quot;Paused&quot;: false,            &quot;Restarting&quot;: false,            &quot;OOMKilled&quot;: false,            &quot;Dead&quot;: false,            &quot;Pid&quot;: 4773,            &quot;ExitCode&quot;: 0,            &quot;Error&quot;: &quot;&quot;,            &quot;StartedAt&quot;: &quot;2022-09-28T17:39:20.57549319Z&quot;,            &quot;FinishedAt&quot;: &quot;0001-01-01T00:00:00Z&quot;        &#125;,        &quot;Image&quot;: &quot;sha256:5d0da3dc976460b72c77d94c8a1ad043720b0416bfc16c52c45d4847e53fadb6&quot;,        &quot;ResolvConfPath&quot;: &quot;/var/lib/docker/containers/82bb167358c7835cae235ad9d3ba2097e5d63ecd7286de50fb26061467d9ef4b/resolv.conf&quot;,        &quot;HostnamePath&quot;: &quot;/var/lib/docker/containers/82bb167358c7835cae235ad9d3ba2097e5d63ecd7286de50fb26061467d9ef4b/hostname&quot;,        &quot;HostsPath&quot;: &quot;/var/lib/docker/containers/82bb167358c7835cae235ad9d3ba2097e5d63ecd7286de50fb26061467d9ef4b/hosts&quot;,        &quot;LogPath&quot;: &quot;/var/lib/docker/containers/82bb167358c7835cae235ad9d3ba2097e5d63ecd7286de50fb26061467d9ef4b/82bb167358c7835cae235ad9d3ba2097e5d63ecd7286de50fb26061467d9ef4b-json.log&quot;,        &quot;Name&quot;: &quot;/hungry_mclean&quot;,        &quot;RestartCount&quot;: 0,        &quot;Driver&quot;: &quot;overlay2&quot;,        &quot;Platform&quot;: &quot;linux&quot;,        &quot;MountLabel&quot;: &quot;&quot;,        &quot;ProcessLabel&quot;: &quot;&quot;,        &quot;AppArmorProfile&quot;: &quot;&quot;,        &quot;ExecIDs&quot;: null,        &quot;HostConfig&quot;: &#123;            &quot;Binds&quot;: null,            &quot;ContainerIDFile&quot;: &quot;&quot;,            &quot;LogConfig&quot;: &#123;                &quot;Type&quot;: &quot;json-file&quot;,                &quot;Config&quot;: &#123;&#125;            &#125;,            &quot;NetworkMode&quot;: &quot;default&quot;,            &quot;PortBindings&quot;: &#123;&#125;,            &quot;RestartPolicy&quot;: &#123;                &quot;Name&quot;: &quot;no&quot;,                &quot;MaximumRetryCount&quot;: 0            &#125;,            &quot;AutoRemove&quot;: false,            &quot;VolumeDriver&quot;: &quot;&quot;,            &quot;VolumesFrom&quot;: null,            &quot;CapAdd&quot;: null,            &quot;CapDrop&quot;: null,            &quot;CgroupnsMode&quot;: &quot;host&quot;,            &quot;Dns&quot;: [],            &quot;DnsOptions&quot;: [],            &quot;DnsSearch&quot;: [],            &quot;ExtraHosts&quot;: null,            &quot;GroupAdd&quot;: null,            &quot;IpcMode&quot;: &quot;private&quot;,            &quot;Cgroup&quot;: &quot;&quot;,            &quot;Links&quot;: null,            &quot;OomScoreAdj&quot;: 0,            &quot;PidMode&quot;: &quot;&quot;,            &quot;Privileged&quot;: false,            &quot;PublishAllPorts&quot;: false,            &quot;ReadonlyRootfs&quot;: false,            &quot;SecurityOpt&quot;: null,            &quot;UTSMode&quot;: &quot;&quot;,            &quot;UsernsMode&quot;: &quot;&quot;,            &quot;ShmSize&quot;: 67108864,            &quot;Runtime&quot;: &quot;runc&quot;,            &quot;ConsoleSize&quot;: [                0,                0            ],            &quot;Isolation&quot;: &quot;&quot;,            &quot;CpuShares&quot;: 0,            &quot;Memory&quot;: 0,            &quot;NanoCpus&quot;: 0,            &quot;CgroupParent&quot;: &quot;&quot;,            &quot;BlkioWeight&quot;: 0,            &quot;BlkioWeightDevice&quot;: [],            &quot;BlkioDeviceReadBps&quot;: null,            &quot;BlkioDeviceWriteBps&quot;: null,            &quot;BlkioDeviceReadIOps&quot;: null,            &quot;BlkioDeviceWriteIOps&quot;: null,            &quot;CpuPeriod&quot;: 0,            &quot;CpuQuota&quot;: 0,            &quot;CpuRealtimePeriod&quot;: 0,            &quot;CpuRealtimeRuntime&quot;: 0,            &quot;CpusetCpus&quot;: &quot;&quot;,            &quot;CpusetMems&quot;: &quot;&quot;,            &quot;Devices&quot;: [],            &quot;DeviceCgroupRules&quot;: null,            &quot;DeviceRequests&quot;: null,            &quot;KernelMemory&quot;: 0,            &quot;KernelMemoryTCP&quot;: 0,            &quot;MemoryReservation&quot;: 0,            &quot;MemorySwap&quot;: 0,            &quot;MemorySwappiness&quot;: null,            &quot;OomKillDisable&quot;: false,            &quot;PidsLimit&quot;: null,            &quot;Ulimits&quot;: null,            &quot;CpuCount&quot;: 0,            &quot;CpuPercent&quot;: 0,            &quot;IOMaximumIOps&quot;: 0,            &quot;IOMaximumBandwidth&quot;: 0,            &quot;MaskedPaths&quot;: [                &quot;/proc/asound&quot;,                &quot;/proc/acpi&quot;,                &quot;/proc/kcore&quot;,                &quot;/proc/keys&quot;,                &quot;/proc/latency_stats&quot;,                &quot;/proc/timer_list&quot;,                &quot;/proc/timer_stats&quot;,                &quot;/proc/sched_debug&quot;,                &quot;/proc/scsi&quot;,                &quot;/sys/firmware&quot;            ],            &quot;ReadonlyPaths&quot;: [                &quot;/proc/bus&quot;,                &quot;/proc/fs&quot;,                &quot;/proc/irq&quot;,                &quot;/proc/sys&quot;,                &quot;/proc/sysrq-trigger&quot;            ]        &#125;,        &quot;GraphDriver&quot;: &#123;            &quot;Data&quot;: &#123;                &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/fcd02afc26d5c1aea385a6b77399b4ec4af0f356359e91041cde84cb9b1237c7-init/diff:/var/lib/docker/overlay2/d95e550d4f62886c70a537524378ebfba5e96932146481454237df6005a0cb8c/diff&quot;,                &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/fcd02afc26d5c1aea385a6b77399b4ec4af0f356359e91041cde84cb9b1237c7/merged&quot;,                &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/fcd02afc26d5c1aea385a6b77399b4ec4af0f356359e91041cde84cb9b1237c7/diff&quot;,                &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/fcd02afc26d5c1aea385a6b77399b4ec4af0f356359e91041cde84cb9b1237c7/work&quot;            &#125;,            &quot;Name&quot;: &quot;overlay2&quot;        &#125;,        &quot;Mounts&quot;: [],        &quot;Config&quot;: &#123;            &quot;Hostname&quot;: &quot;82bb167358c7&quot;,            &quot;Domainname&quot;: &quot;&quot;,            &quot;User&quot;: &quot;&quot;,            &quot;AttachStdin&quot;: false,            &quot;AttachStdout&quot;: false,            &quot;AttachStderr&quot;: false,            &quot;Tty&quot;: false,            &quot;OpenStdin&quot;: false,            &quot;StdinOnce&quot;: false,            &quot;Env&quot;: [                &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;            ],            &quot;Cmd&quot;: [                &quot;/bin/bash&quot;,                &quot;-c&quot;,                &quot;while true;do echo print logs;sleep 1;done &quot;            ],            &quot;Image&quot;: &quot;centos&quot;,            &quot;Volumes&quot;: null,            &quot;WorkingDir&quot;: &quot;&quot;,            &quot;Entrypoint&quot;: null,            &quot;OnBuild&quot;: null,            &quot;Labels&quot;: &#123;                &quot;org.label-schema.build-date&quot;: &quot;20210915&quot;,                &quot;org.label-schema.license&quot;: &quot;GPLv2&quot;,                &quot;org.label-schema.name&quot;: &quot;CentOS Base Image&quot;,                &quot;org.label-schema.schema-version&quot;: &quot;1.0&quot;,                &quot;org.label-schema.vendor&quot;: &quot;CentOS&quot;            &#125;        &#125;,        &quot;NetworkSettings&quot;: &#123;            &quot;Bridge&quot;: &quot;&quot;,            &quot;SandboxID&quot;: &quot;0cd61c994ce552f0c40d92076a80223aa1ca509814ced1ba2e05ca3006f800a1&quot;,            &quot;HairpinMode&quot;: false,            &quot;LinkLocalIPv6Address&quot;: &quot;&quot;,            &quot;LinkLocalIPv6PrefixLen&quot;: 0,            &quot;Ports&quot;: &#123;&#125;,            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/0cd61c994ce5&quot;,            &quot;SecondaryIPAddresses&quot;: null,            &quot;SecondaryIPv6Addresses&quot;: null,            &quot;EndpointID&quot;: &quot;4791507c4b3d9221dcca506844705803e4d6faafeacfa206225650490224ba02&quot;,            &quot;Gateway&quot;: &quot;172.17.0.1&quot;,            &quot;GlobalIPv6Address&quot;: &quot;&quot;,            &quot;GlobalIPv6PrefixLen&quot;: 0,            &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,            &quot;IPPrefixLen&quot;: 16,            &quot;IPv6Gateway&quot;: &quot;&quot;,            &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,            &quot;Networks&quot;: &#123;                &quot;bridge&quot;: &#123;                    &quot;IPAMConfig&quot;: null,                    &quot;Links&quot;: null,                    &quot;Aliases&quot;: null,                    &quot;NetworkID&quot;: &quot;2893fe225a852d859fb8e831ff668623b9f220c3f47a8b1b83bb31691a8961b5&quot;,                    &quot;EndpointID&quot;: &quot;4791507c4b3d9221dcca506844705803e4d6faafeacfa206225650490224ba02&quot;,                    &quot;Gateway&quot;: &quot;172.17.0.1&quot;,                    &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,                    &quot;IPPrefixLen&quot;: 16,                    &quot;IPv6Gateway&quot;: &quot;&quot;,                    &quot;GlobalIPv6Address&quot;: &quot;&quot;,                    &quot;GlobalIPv6PrefixLen&quot;: 0,                    &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,                    &quot;DriverOpts&quot;: null                &#125;            &#125;        &#125;    &#125;]\n进入当前正在运行的容器\n123# 命令docker exec -it 容器ID /bin/bahs  # 进入容器后开启一个新的终端docker attch 容器ID # 进入容器正在执行的终端，不会启动新的进程\n从容器内拷贝文件到主机上\n1234docker cp 容器ID:容器内路径 目标路径[root@vm22 ~]# docker cp cfb377b1b56f:/home/docker-cp /home[root@vm22 ~]# ls /homedocker-cp  docker-test-volume  mysql  test","slug":"Docker的基础命令","date":"2021-10-07T07:03:20.000Z","categories_index":"Docker","tags_index":"Docker","author_index":"Brevin"},{"id":"a4200f3b83fd12fc52df8fa786ffcf93","title":"Nginx负载均衡","content":"\n上篇文章讲了nginx的常见模块，这边文章将为大家讲一下nginx的负载均衡。\n1.准备工作这里我用三台服务器来做演示：\n\nNginx负载均衡:192.168.10.22:80\nNginx Web1:192.168.10.23:80\nNginx Web2:192.168.10.24:80为了方便演示我这里用默认的80端口\n\n为了验证效果我们写一个简单html主页：\n12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;这是服务器1&lt;/title&gt; &lt;/head&gt;&lt;body&gt;    &lt;center&gt;        &lt;h1&gt;这是服务器1&lt;/h1&gt;    &lt;/center&gt;&lt;/body&gt;&lt;/html&gt;\n将以上代码复制两份命名为index.html ，注意将第二份&lt;title&gt;这是服务器1&lt;/title&gt; 改成2。##2.配置Web服务器首先将index.html文件上传到两台服务器上服务器上\n123$ mkdir /data$ mkdir /data/www# 创建web目录\n创建nginx配置文件/etc/nginx/conf.d/web.confNginx的安装请参考上一篇文章\n123456789101112131415161718192021$ vim /etc/nginx/conf.d/web.conf# 复制下面配置文件server  &#123;        listen  80;        server_name     localhost;         location / &#123;        root /data/www;  # index.html文件的目录        index   index.html;        &#125;        error_page 404  /404.html;        error_page 500 502 503 504 /50x.html;        location = /50x.html &#123;        root /usr/share/nginx/html;        &#125;&#125;# 检查配置文件$ nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful# 重新加载nginx配置$ nginx -s reload\n打开浏览器输入&lt;ip地址&gt;可以看到以下页面，说明web服务器配置成功。第二台web配置和第一台一样##3.配置nginx负载均衡首先我们创建配置文件/etc/nginx/conf.d/1.conf\n1234567891011121314151617181920212223$ vim /etc/nginx/conf.d/1.conf# 写入下面的配置文件server  &#123;        listen  80;        server_name     localhost;        location / &#123;        proxy_pass http://www;        # 这里的www是自己设置的负载均衡池的名称        &#125;        error_page 404  /404.html;        error_page 500 502 503 504 /50x.html;        location = /50x.html &#123;        root /usr/share/nginx/html;        &#125;&#125;# 负载均衡池，这里我用的轮询模式upstream  www &#123;     server    192.168.10.23;     server    192.168.10.24;&#125;# 检查nginx配置文件$ nignx -t$ nginx -s reload\n在浏览器里输入&lt;192.168.10.22&gt;我们可以看到页面正常显示。我们再次刷新一下页面：可以看到访问顺序是：服务器1&gt;服务器2&gt;服务器1&gt;服务器2，说明负载均衡配置成功。\n##3.Nginx负载均衡模式1.轮询轮询方式是Nginx负载默认的方式，顾名思义，所有请求都按照时间顺序分配到不同的服务上，如果服务Down掉，可以自动剔除，如下配置后轮训10.23服务和10.24服务。\n1234upstream  www &#123;     server    192.168.10.23;     server    192.168.10.24;&#125;\n2.权重指定每个服务的权重比例，weight和访问比率成正比，通常用于后端服务机器性能不统一，将性能好的分配权重高来发挥服务器最大性能，如下配置后10.23服务的访问比率会是10.24服务的二倍。\n1234upstream  dalaoyang-server &#123;     server    192.168.10.23  weight=1;     server    192.168.10.24  weight=2;&#125;\n3.iphash每个请求都根据访问ip的hash结果分配，经过这样的处理，每个访客固定访问一个后端服务，如下配置（ip_hash可以和weight配合使用）。\n12345upstream  dalaoyang-server &#123;       ip_hash;        server    192.168.10.23 weight=1;       server    192.168.10.24 weight=2;&#125;\n4.最少连接将请求分配到连接数最少的服务上。\n12345upstream  dalaoyang-server &#123;       least_conn;       server    192.168.10.23 weight=1;       server    192.168.10.24 weight=2;&#125;\n5.fair按后端服务器的响应时间来分配请求，响应时间短的优先分配。\n12345upstream  dalaoyang-server &#123;       server    192.168.10.23 weight=1;       server    192.168.10.24 weight=2;       fair;&#125;","slug":"Nginx负载均衡","date":"2020-06-24T12:21:33.000Z","categories_index":"Nginx","tags_index":"Nginx,Linux,教程","author_index":"Brevin"},{"id":"01b2f95cf7b3ad8e6df19f8a3034e6c8","title":"Nginx快速入门","content":"\n\n\n\n\n\n\n\n\n\nNginx(“engine x”)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。在高连接并发的情况下，Nginx是Apache服务器不错的替代品。##安装Nginx这里我用CentOS为例：1.安装先决条件\n1$ yum install yum-utils\n2.设置yum存储库，将下面内容写入/etc/yum.repos.d/nginx.repo\n12345678$ vim /etc/yum.repos.d/nginx.repo[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true\n3.安装Nginx\n12$ yum update$ yum install nginx\n4.验证是否安装成功启动Nginx\n12345678910$ nginx查看端口80已被nginx监听$ netstat -ntlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      666/sshd            tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      799/master          tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      23779/nginx: master tcp6       0      0 :::22                   :::*                    LISTEN      666/sshd            tcp6       0      0 ::1:25                  :::*                    LISTEN      799/master\n5.设置防火墙如果在浏览器里输入ip地址发现无法访问此网站，那有可能是防火墙80端口没有开放。\n123456编辑iptables配置文件$ vim /etc/sysconfig/iptables添加开放80端口 -A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEP重启iptables$ systemctl restart iptables\n们刷新页面出现Welcome to nginx!说明安装配置成功![welcone nginx.png](/images/Nginx快速入门/welcome to nginx.png)##Nginx常用命令\n123456$ nginx           — 启动Nginx$ nginx -t        — 检查Nginx配置文件$ nginx -s stop   — 快速关闭$ nginx -s quit   — 正常关闭$ nginx -s reload — 重新加载配置文件$ nginx -s reopen — 重新打开日志文件\n##Nginx主模块基本命令daemon语法: daemon on | off缺省值:on是否以守护进程的方式运行nginx，守护进程是指脱离终端并且在后台运行的进程，关闭守护进程可以方便我们调试nginx。\n1daemon off;\nmaster_process语法:master_process on | off缺省值:on是否以master/worker方式逬行工作，在实际的环境中nginx是以一个master逬程管理多个worker进程的方式运行的，关闭后nginx就不会fork出worker子进程来处理请求，而是用master进程自身来处理请求worker_processes number;默认1,在master/worker运行方式下worker进程的数目，一般情况下用户要配置与CPU内核数相等的worker进程。\n1master_process off;\n\n\n\n\n\n\n\n\n\n\n生产环境中不要使用”daemon”和”master_process”指令，这些选项仅用于开发调试。\nerror_log语法:error_log file [ debug | info | notice | warn | error | crit ]缺省值:$&#123;prefix&#125;/logs/error.logNginx 添加 –with-debug 编译参数, 你还能够使用以下配置:\n12error_log LOGFILE [ debug_core | debug_alloc | debug_mutex | debug_event]: | debug_http | debug_imap ;\ninclude语法:include file | *缺省值:none你可以在任意地方使用include指令实现配置文件的包含，类似于apache中的include方法，可减少主配置文件。\n```指令还支持像下面配置一样的全局包含的方法，例如包含一个目录下所有以\".conf\"结尾的文件:12```include vhosts/*.conf;\npid语法:pid file缺省值:compile-time option Example:进程id存储文件。可以使用 kill -HUP cat /var/log/nginx.pid\\ 对Nginx进行配置文件重新加载。\n1pid /var/log/nginx.pid;\nuser语法:user user [group]缺省值:nobody nobody指定Nginx Worker进程运行用户，默认是nobody帐号。\n例如:\n1user www users;\nworker_processes语法:worker_processes number缺省值:1nginx可以使用多个worker进程，原因如下：\n1.使用SMP2.当工作程序在磁盘I / O上阻塞时减少延迟3.当使用select（）/ poll（）时限制每个进程的连接数\n1worker_processes 4;\n##Nginx处理HTTP的核心功能模块\n基本指令alias语法:alias file-path|directory-path;缺省值:no使用字段:location该伪指令分配用于指定位置的路径。 请注意，它看起来类似于root伪指令，但是文档root不会改变，只是用于请求的文件系统路径。\n1234location  /i/ &#123; alias   /spool/w3/images/;&#125;# 请求“ /i/1.jpg”将返回文件“ /spool/w3/images/1.jpg\nkeepalive_timeout语法: keepalive_timeout [ time ]缺省值:keepalive_timeout 75使用字段:http, server, location第一个参数为与客户端的保持活动连接分配超时。 在此时间之后，服务器将关闭连接。\n可选的第二个参数指定了答应头Keep-Alive: timeout=time的```time````值，这个值可以使一些浏览器知道什么时候关闭连接，以便使服务器不用重复关闭，如果不指定这个参数，nginx不会在答应头中发送Keep-Alive信息。\n下面列出了一些服务器如何处理包含Keep-Alive的答应头：\n\nMSIE和Opera会忽略“ Keep-Alive：timeout = ”标头。\nMSIE使连接保持活动状态约60-65秒，然后发送TCP RST。\nOpera可以长时间保持连接状态。\nMozilla使连接保持活动状态N大约1-10秒。\nKonqueror使连接保持活动状态约N秒钟。\n\nlisten语法:listen address:port [ default [ backlog=num | rcvbuf=size | sndbuf=size | accept_filter=filter | deferred | bind | ssl ] ]缺省值:listen 80使用字段:serverlisten指令指定封闭服务器{…}块接受的地址和端口。 可以仅指定地址，仅端口或服务器名称作为地址。\n12345listen 127.0.0.1:8000;listen 127.0.0.1;listen 8000;listen *:8000;listen localhost:8000;\nIPv6地址（0.7.36）设置：\n12listen [::]:8000; listen [fe80::1];\nlocation语法:location [=|~|~*|^~] /uri/ &#123; ... &#125;缺省值:no使用字段:server这个参数根据URL的不同需求来进行配置，可以使用字符串与正则表达式匹配，如果要使用正则表达式，你必须指定下列前缀：\n\n~*不区分大小写\n～区分大小写1234567891011121314151617location  = / &#123;  # 只匹配 / 的查询  [ configuration A ] &#125;location  / &#123;  # 匹配任何以 / 开头的查询  # 但是正则表达式与一些较长的字符串将首先匹配  [ configuration B ] &#125;location ^~ /images/ &#123;  # 匹配任何以/images/开始的查询并且停止搜索，不检查正则表达式  [ configuration C ] &#125;location ~* \\.(gif|jpg|jpeg)$ &#123;  # 匹配任何以gif,jpg,jpeg结尾的文件，但是所有/images/目录请求将在Configuration C 中处理  [ configuration D ] &#125;\n\nresolver_timeout语法:resolver_timeout time使用字段:http,server,location解析超时时间。如：\n1resolver_timeout 5s;\nroot语法:root path缺省值:root html使用字段:http,server,location,location中if字段请求到达后的文件根目录\n123location  /i/  &#123;  root  /spool/w3&#125;\n如果亲求/i/top.jpg文件，nginx将转到/spool/w3/i/top.jpg文件。你可以在参数中使用变量。注意：在亲求中root会添加这个location到它的后面，即/i/top.jpg并不会请求/spool/w3/i/top.jpg文件，如果要实现上述类似与apache alias的功能，可以使用alias指令。server语法:server&#123;...&#125;缺省值:no使用字段:httpserver字段包含虚拟主机的配置。没有明确的机制来分开基于域名（请求中的主机头）和基于IP的虚拟主机。可以通过listen指令来指定必须连接到这个server块的所有地址和端口，并且在server_name指令中可以指定所有的域名。server_name语法:server_name name [...]使用字段:server将HTTP请求的主机头与nginx配置文件中的server字段中指定的参数进行匹配，并且找出第一个匹配结果。\n\n完整的静态名称\n名称开头带有通配符的名称— * .example.com\n名称末尾带有通配符的名称www.example.*\n具有正则表达式的名称\n\n如果不匹配，将根据以下顺序使用配置文件中的[#server服务器{…}]块：\n\nlisten指令被标记为default的server字段\n第一个出现listen的server字段\n\n","slug":"Nginx快速入门","date":"2020-06-22T10:23:05.000Z","categories_index":"Nginx","tags_index":"Nginx,Linux","author_index":"Brevin"},{"id":"8e903f5d8f6275843e8b600d4505da68","title":"Docker的安装和部署","content":"\n在Ubuntu中安装Docker要安装Docker Engine，您需要以下Ubuntu版本之一的64位版本：\n\nUbuntu Eoan 19.10\nUbuntu Bionic 18.04（LTS）\nUbuntu Xenial 16.04（LTS）\n其他最新版本\n\n安装前的检查\n检查内核版本Docker需要3.10+内核的linux操作系统。12$ uname -aLinux ubuntu 5.4.0-26-generic #30-Ubuntu SMP Mon Apr 20 16:58:30 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\n检查Device Mapper12$ ls -l /sys/class/misc/device-mapperlrwxrwxrwx 1 root root 0 May 24 08:45 /sys/class/misc/device-mapper -&gt; ../../devices/virtual/misc/device-mapper\n卸载旧的版本\n较旧的Docker版本名称为docker，docker.io或docker-engine。 如果已安装，请卸载它们：1$ sudo apt-get remove docker docker-engine docker.io containerd runc\n如果提示以下结果,说明系统中没有安装较久版本的Docker。1234Reading package lists... DoneBuilding dependency tree       Reading state information... DoneE: Unable to locate package docker-engine\n设置存储库\n更新apt软件包索引并安装软件包以允许apt通过HTTPS使用存储库：\n\n12345678$ sudo apt-get update$ sudo apt-get install \\    apt-transport-https \\    ca-certificates \\    curl \\    gnupg-agent \\    software-properties-common\n\n添加Docker的官方GPG密钥：\n\n12$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -OK\n通过搜索指纹的后8个字符，验证您现在是否拥有带有指纹的密钥 。\n12345sudo apt-key fingerprint 0EBFCD88pub   rsa4096 2017-02-22 [SCEA]         9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88uid    [ unknown] Docker Release (CE deb) &lt;docker@docker.com&gt;sub   rsa4096 2017-02-22 [S]\n\n使用以下命令来设置稳定的存储库。1234$ sudo add-apt-repository \\   &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\   $(lsb_release -cs) \\   stable&quot;\n安装Docker\n更新apt包索引，并安装最新版本的Docker Engine和容器。12$ sudo apt-get update$ sudo apt-get install docker-ce docker-ce-cli containerd.io\n通过运行hello-world 映像来验证是否正确安装了Docker Engine 。123456789101112$ sudo docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub.    (amd64) 3. The Docker daemon created a new container from that image which runs the    executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it    to your terminal.\n终端出现Hello from Docker!提示，说明Docker已经成功的安装到您的系统中。\n\n配置阿里云镜像加速\n登陆阿里云后再产品中找到容器镜像服务。\n\n进入控制台后点击镜像工具-镜像加速器。\n\n根据操作文档配置镜像加速。\n12345678$ sudo mkdir -p /etc/docker$ sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123;  &quot;registry-mirrors&quot;: [&quot;https://&lt;加速器地址&gt;&quot;]&#125;EOF$ sudo systemctl daemon-reload$ sudo systemctl restart docker\n\n","slug":"Docker的安装和部署","date":"2020-05-26T09:33:20.000Z","categories_index":"Docker","tags_index":"Docker","author_index":"Brevin"},{"id":"ae3533aad9ffb390f0136b0f330276f7","title":"Docker相关技术简介","content":"\n\n\n\n\n\n\n\n\n\nDocker 是一个开源的应用容器引擎，基于Go 语言并遵从 Apache2.0 协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。\nDocker简介什么是容器？容器是一种虚拟化解决方案，相对于传统虚拟机不同。传统的虚拟机是用中间层，将一台或多台独立的机器虚拟运行在硬件之上。而容器则是直接运行操作系统之上的用户空间，因此容器虚拟又被称为操作系统虚拟化。由于容器依赖于操作系统的特性，因此容器只能运行相同或相似内核的操作系统。\nDocker使用的技术依赖于Linux内核的Namespace和Cgroups (Control Group) 等特性，所以Docker容器只能运行Linux类系统而不能运行Windows系统。这也是容器技术相对虚拟机技术系统灵活性上的劣势。\n\nDocker与虚拟机对比\n启动速度启动虚拟机需要先启动虚拟机的操作系统，再启动应用，这个过程非常慢。启动Docker相当于启动宿主机操作系统上的一个进程，为秒级别。\n\n资源占用更小从图中我们可以看到，使用虚拟机部署应用不但包含了应用和其所依赖的库，还包含了完整的操作系统;占用大量的磁盘空间、内存和CPU资源。Docker只需要应用和其依赖的库，在运行时占用很少的资源。\n\n镜像与容器镜像是一种静态的结构，可以看成面向对象里面的类，而容器是镜像的一个实例。镜像包含着容器运行时所需要的代码以及其它组件，它是一种分层结构，每一层都是只读的（read-only layers）。构建镜像时，会一层一层构建，前一层是后一层的基础。镜像的这种分层存储结构很适合镜像的复用以及定制。构建容器时，通过在镜像的基础上添加一个可写层（writable layer），用来保存着容器运行过程中的修改。\n\n\nDocker的特点\n提供简单轻量的建模方式用户只需要几分钟就可以将自己的程序Docker化。大多是Docker容器只需要不到一秒就可以启动。由于去除了管理程序的开销，Docker容器拥有更高的性能，同时一台宿主机中也可以运行更多的容器。使用户可以尽可能的利用系统资源。\n\n职责的逻辑分离使用Docker，开发人员只需要关心容器中运行的应用程序，而运维人员只需要关心管理容器。\n\n快速高效的发开周期缩短代码从开发到测试到部署上线运行的周期，让应用具备可移植性。在容器中开发也就避免额外的调试、和部署上的开销，这样就有效的缩短了产品上线的周期。\n\n鼓励使用面向服务的架构Docker推荐单个容易只运行一个容器，这样就形成一个分布式的应用程序模型。在这样的模型下，应用程序和服务可以表现为一系列内部互联的容器，从而使分布式应用程序扩展或调试应用程序都变得非常简单。\n\n\nDocker的使用场景\n使用Docker容器开发、测试、部署服务\n创建隔离的运行环境\n搭建测试环境\n构建多用户的平台服务(PaaS)基础设施\n提供软件即服务(SaaS)应用程序\n高性能、超大规模的宿主机部署\n\nDocker优缺点\n\n\n\n\n\n\n\n\n参考链接:https://cloud.tencent.com/developer/article/1457282\n\n部署方便\n\n搭建环境这一步往往会耗费我们好几个小时的时间，而且其中一个小问题可能需要找很久才能够解决。你还会得到关于环境搭建方面的团队其他成员的求助。而有了容器之后，这些都变得非常容易，你的开发环境就只是一个或者几个容器镜像的地址，最多再需要一个控制部署流程的执行脚本。2. 部署安全\n当我们收到一个bug反馈的时候，很多时候心里面的第一反应一定是“我本地是好的啊”！ 这种情况的发生就在于环境的不一致，我们在开发过程中的调试往往不能保证其他环境的问题，但是我们却要为此买单，这真是一件令人苦恼的事情。有了容器之后，这将很少发生。我们可以通过容器技术将开发环境和测试环境以及生产环境保持版本和依赖上的统一，保证代码在一个高度统一的环境上执行。而测试环境的统一，也同样能解决CI流程对环境的要求。\n分布式技术和扩容需求日益增长的今天，如果运维能够使用容器技术来进行环境的部署，不仅仅在部署时间上节省不少，也能把很多因为人工配置环境产生的失误降到最低。\n\n隔离性好\n\n不管是开发还是生产，往往我们一台机器上可能需要跑多个服务，而服务各自需要的依赖配置不尽相同，假如说两个应用需要使用同一个依赖，或者两个应用需要的依赖之间会有一些冲突，这个时候就很容易出现问题了。 所以同一台服务器上不同应用提供的不同服务，最好还是将其隔离起来。而容器在这方面有天生的优势，每一个容器就是一个隔离的环境，你对容器内部提供服务的要求，容器可以自依赖的全部提供。这种高内聚的表现可以实现快速的分离有问题的服务，在一些复杂系统中能实现快速排错和及时处理。(当然需要说明的是，这个隔离性只是相对于服务器比较的，虚机技术要拥有更好的隔离性)\n\n快速回滚\n\n容器之前的回滚机制，一般需要基于上个版本的应用重新部署，且替换掉目前的问题版本。在最初的时代，可能是一套完整的开发到部署的流程，而执行这一套流程往往需要很长的时间。在基于git的环境中，可能是回退某个历史提交，然后重新部署。这些跟容器技术相比都不够快，而且可能会引起新的问题（因为是基于新版本的修改）。而容器技术天生带有回滚属性，因为每个历史容器或者镜像都会有保存，而替换一个容器或者某个历史镜像是非常快速和简单的。\n\n成本低\n\n这可能是一个最明显和有用的优点了，在容器出现之前，我们往往构筑一个应用就需要一台新的服务器或者一台虚机。服务器的购置成本和运维成本都很高，而虚机需要占用很多不必要的资源。相比之下，容器技术就小巧轻便的多，只需要给一个容器内部构建应用需要的依赖就可以了，这也是容器技术发展迅速的最主要原因。\n\n管理成本更低\n\n随着容器技术的不断普及和发展，随之而来的容器管理和编排技术也同样得到发展。诸如Docker Swarm，Kubernetes, Mesos等编排工具也在不断的迭代更新，这让容器技术在生产环境中拥有了更多的可能性和更大的发挥空间。而随着大环境的发展，docker等容器的使用和学习的成本也是愈发降低，成为更多开发者和企业的选择。\n说了这么多的优点，容器也有一些问题是没有解决的。上一代方案基本就是基于虚机技术的云方案，能有效增加服务器的使用效率，达到节省成本的目的，而容器技术在此基础上更进一步地优化了资源的使用率。但是仍然有一些问题，是我们在选择服务资源架构场景中需要考虑的：\n\n 隔离性\n\n基于hypervisor的虚机技术，在隔离性上比容器技术要更好，它们的系统硬件资源完全是虚拟化的，当一台虚机出现系统级别的问题，往往不会蔓延到同一宿主机上的其他虚机。但是容器就不一样了，容器之间共享同一个操作系统内核以及其他组件，所以在收到攻击之类的情况发生时，更容易通过底层操作系统影响到其他容器。当然，这个问题可以通过在虚机中部署容器来解决，可是这样又会引出新的问题，比如成本的增加以及下面要提到的问题：性能。\n\n性能\n\n不管是虚机还是容器，都是运用不同的技术，对应用本身进行了一定程度的封装和隔离，在降低应用和应用之间以及应用和环境之间的耦合性上做了很多努力，但是随机而来的，就会产生更多的网络连接转发以及数据交互，这在低并发系统上表现不会太明显，而且往往不会成为一个应用的瓶颈（可能会分散于不同的虚机或者服务器上），但是当同一虚机或者服务器下面的容器需要更高并发量支撑的时候，也就是并发问题成为应用瓶颈的时候，容器会将这个问题放大，所以，并不是所有的应用场景都是适用于容器技术的。\n\n存储方案\n\n容器的诞生并不是为OS抽象服务的，这是它和虚机最大的区别，这样的基因意味着容器天生是为应用环境做更多的努力，容器的伸缩也是基于容器的这一disposable特性，而与之相对的，需要持久化存储方案恰恰相反。这一点docker容器提供的解决方案是利用volume接口形成数据的映射和转移，以实现数据持久化的目的。但是这样同样也会造成一部分资源的浪费和更多交互的发生，不管是映射到宿主机上还是到网络磁盘，都是退而求其次的解决方案。\n随着硬件技术和网络技术的迭代发展，容器技术的缺点会变得越来越不那么明显，而且随着容器技术的发展和普及，对应的解决方案也会越来越多。所以总体来看，docker等容器技术会朝着更加普及的趋势走近我们技术领域。 也希望每一位热爱技术的小伙伴们能更加了解这些新技术，让它们能够更好的为我们服务。\n","slug":"Docker相关技术简介","date":"2020-05-12T14:14:20.000Z","categories_index":"Docker","tags_index":"Docker","author_index":"Brevin"},{"id":"70dd287eea3c3b1a2c451ddd5cf0b7eb","title":"Frp内网穿透","content":"Frp内网穿透Frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和 https 应用协议提供了额外的能力，且尝试性支持了点对点穿透。项目地址：https://github.com/fatedier/frp\n安装FrpFRP 采用 Go 语言开发，支持 Windows、Linux、MacOS、ARM等多平台部署。这里我用的是Centos 8，为了方便管理我们把解压后的目录重命名为 frp\n123wget https://github.com/fatedier/frp/releases/download/v0.33.0/frp_0.33.0_linux_amd64.tar.gztar xzvf frp_0.33.0_linux_amd64.tar.gzmv frp_0.33.0_linux_amd64 frp\n\nFRP 服务端配置配置 FRP 服务端的前提条件是需要一台具有公网 IP的设备。\nFRP 默认给出两个服务端配置文件，一个是简版的 frps.ini，另一个是完整版本 frps_full.ini。通过frps.ini这个配置可以快速的搭建起一个 FRP 服务端。\n12345678910$ cat frps.ini[common]bind_port = 7000 默认配置中监听的是 7000 端口，可根据自己实际情况修改。启动 FRP 服务端$ ./frps -c ./frps.ini2020/05/08 01:02:31 [I] [service.go:178] frps tcp listen on 0.0.0.0:70002020/05/08 01:02:31 [I] [root.go:209] start frps success\n\nFRP 客户端配置编辑 frpc.ini\n1234567891011121314151617181920212223242526272829303132$ vim frpc.ini[common]#server_addr 为 FRP 服务端的公网 IPserver_addr = 192.168.50.11#server_port 为 FRP 服务端监听的端口server_port = 7000# Linu SSH服务[ssh]#网络协议type = tcp#填写客户端主机IPlocal_ip = 192.168.50.12#Linux远程端口local_port = 22#代理到服务端的端口这里我用6000remote_port = 6000# Windows远程服务器[rdp]#网络协议type = tcp#填写客户端主机IPlocal_ip = 192.168.50.13#Windows远程端口，默认是3389local_port = 3389#代理到服务端的端口这里我用23389remote_port = 23389启动 FRP 客户端$ ./frpc -c ./frpc.ini2020/05/07 23:18:53 [I] [service.go:282] [adbfac88ab64d72f] login to server success, get run id [adbfac88ab64d72f], server udp port [0]2020/05/07 23:18:53 [I] [proxy_manager.go:144] [adbfac88ab64d72f] proxy added: [ssh]2020/05/07 23:18:53 [I] [control.go:179] [adbfac88ab64d72f] [ssh] start proxy success\n我们查看服务端的提示\n123452020/05/08 07:18:49 [I] [service.go:178] frps tcp listen on 0.0.0.0:70002020/05/08 07:18:49 [I] [root.go:209] start frps success2020/05/08 07:18:55 [I] [service.go:432] [adbfac88ab64d72f] client login info: ip [192.168.50.12:39836] version [0.33.0] hostname [] os [linux] arch [amd64]2020/05/08 07:18:55 [I] [tcp.go:63] [adbfac88ab64d72f] [ssh] tcp proxy listen port [6000]2020/05/08 07:18:55 [I] [control.go:445] [adbfac88ab64d72f] new proxy [ssh] success\n可以看到我们的SSH服务已经成功连接到服务端的6000端口。\n1234$ ssh root@192.168.50.11 -p 6000The authenticity of host &#x27;[192.168.50.11]:6000 ([192.168.50.11]:6000)&#x27; can&#x27;t be established.ECDSA key fingerprint is SHA256:jwBjW8YC0VaFaTRTJaB8EJDuAZFZ6MBlh6pJbSVjngU.Are you sure you want to continue connecting (yes/no)?\n可以看到已经可以成功连接到服务器。\n将服务添加至systemctl这里以frp服务端为例\n将frp/systemd目录下的frps.service复制到/etc/systemd/system/目录下\n12345678$ cp /frp/systemd/frps.service /etc/systemd/system复制配置文件和二进制文件到相对应的目录$ cp /frps /usr/bin$ cp /frps.ini /etc/frp重新加载服务配置$ systemctl daemon-reload设置为开机启动$ systemctl enable frps.service\n到这里就完成了Frp服务的所有配置，这样就能随时随地的访问我们家中的电脑了。\n","slug":"Frp内网穿透","date":"2020-05-08T07:02:40.000Z","categories_index":"教程","tags_index":"-Linux -教程","author_index":"Brevin"},{"id":"d5477574fa77bf54e6e43f047273c678","title":"Samba快速入门","content":"安装Samba1234567[root@localhost ~]# yum install samba -y[root@localhost ~]# cd /etc/samba/[root@localhost samba]# lslmhosts  smb.conf  smb.conf.example[root@localhost samba]# mv smb.conf smb.conf.bak[root@localhost samba]# grep -v &quot;#&quot; smb.conf.bak &gt; smb.conf \n配置文件smb.conf12345678910111213141516171819202122[root@localhost samba]# vim smb.conf[global]        workgroup = SAMBA        security = user         passdb backend = tdbsam        printing = cups        printcap name = cups        load printers = yes        cups options = raw[myshare]                ##共享文件目录路径                path=/opt/wbm                         browseable=yes                create mask=0644                directory mask=0755                ##允许访问的用户                valid users=wbm                ##允许写入的用户                write list=wbm  \n创建用户1[root@localhost samba]#useradd wbm\n给用户设置密码1[root@localhost samba]#smbpasswd -a wbm \n列出smb用户列表12[root@localhost samba]#pdbedit -L  wbm:1000:\n创建Samba共享目录123[root@localhost ~]#mkdir /opt/wbm[root@localhost ~]#chmod 777 /opt/wbm[root@localhost ~]#systemctl start smb.service \n挂在samba共享1234[root@vm22 ~]# mount -t cifs //192.168.10.21/wbm /opt/wbm/ -o username=wbm,password=qwer1.2.3.[root@vm22 ~]# cd /opt/wbm/[root@vm22 wbm]# lsInstall_nginx.sh\n开机自动挂载12345[root@vm22 wbm]# vim /etc/fstab#在末尾处添加//192.168.10.21 /opt/wbm    cifs username=wbm,password=qwer1.2.3. 0 0","slug":"Samba快速入门","date":"2019-06-27T09:35:23.000Z","categories_index":"教程","tags_index":"Linux,教程","author_index":"Brevin"},{"id":"065300218eb4a63be27d42f44bfa37db","title":"搭建LAMP环境","content":"1搭建 MySQL 数据库安装 MySQL使用 yum 安装 MySQL：\n1yum install mysql-server -y\n安装完成后，启动 MySQL 服务：\n1service mysqld restart\n设置 MySQL 账户 root 密码：[?]\n1/usr/bin/mysqladmin -u root password &#x27;Password&#x27;\n\n2安装 Apache 服务安装 Apache使用 yum 安装 Apache\n1yum install httpd -y\n启动 Apache 服务：\n1service httpd start\n3安装 PHP安装 PHP 和 PHP-MYSQL 支持工具：使用 yum 安装 PHP：[?]\n1yum install php php-mysql -y\nCentOS 6 默认已经安装了 php-mysql，下面命令执行的可能会提示已经安装。\n4检查安装是否成功检验 PHP 是否安装成功我们在 /var/www/html 目录下创建一个info.php文件来检查php是否安装成功，示例代码参考如下\n示例代码：/var/www/html/info.php\n1&lt;?php phpinfo(); ?&gt;\n重启 Apache 服务：\n1service httpd restart\n此时，访问 http://&lt;您的 CVM IP 地址&gt;/info.php 可浏览到我们刚刚创建的 info.php 页面了\n","slug":"搭建LAMP环境","date":"2019-06-14T10:11:41.000Z","categories_index":"教程","tags_index":"Linux,教程","author_index":"Brevin"}]